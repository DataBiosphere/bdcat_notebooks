{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Bring your own data to your Terra workspace and organize it in a data table\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "If you are planning to upload many files to your Terra workspace, we recommend you organize your data into a Terra\ndata table. This is especially helpful when you plan to run workflows with this data because you can avoid pasting\nin the \"gs://\" links to every file and instead use Terra's helpful UI features.\n\n\nIn this example, we introduce tools to help you:\n\n1. Programmatically upload data from your local machine to your Terra workspace using `gsutil cp`.\n\n2. Programmatically generate a data table that conatins your samples CRAM and CRAI files. The end result will look\n   like this table:\n\n| sample_id | cram       | crai      |\n| --------- | ---------  | --------- |\n| NWD1      | NWD1.cram  | NWD1.crai |\n| NWD2      | NWD2.cram  | NWD2.crai |\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "#install necessary libraries\n%pip install --upgrade --no-cache-dir terra-notebook-utils\n%pip install --upgrade --no-cache-dir gs-chunked-io\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "import io\nimport os\nfrom uuid import uuid4\nfrom firecloud import fiss\nfrom collections import defaultdict\nfrom typing import Any, List, Set, Dict, Iterable\nfrom terra_notebook_utils import gs\n\ngoogle_project = os.environ['GOOGLE_PROJECT']\nworkspace = os.environ['WORKSPACE_NAME']\n\ndef upload_data_table(tsv):\n    resp = fiss.fapi.upload_entities(google_project, workspace, tsv, model=\"flexible\")\n    resp.raise_for_status()\n\ndef upload_rows(table: str, rows: List[Dict[str, Any]]):\n    assert rows\n    columns = sorted(rows[0].keys())\n    tsv_data = \"\\t\".join([f\"{table}_id\", *columns])\n    for i, row in enumerate(rows):\n        tsv_data += os.linesep + \"\\t\".join([f\"{i}\", *[row[c] for c in columns]])\n    upload_data_table(tsv_data)\n\ndef upload_columns(table: str, columns: Dict[str, List[Any]]):\n    column_headers = sorted(columns.keys())\n    number_of_rows = len(columns[set(columns.keys()).pop()])\n    tsv_data = \"\\t\".join([f\"{table}_id\", *column_headers])\n    for i in range(number_of_rows):\n        tsv_data += os.linesep + \"\\t\".join([f\"{i}\", *[columns[h][i] for h in column_headers]])\n    upload_data_table(tsv_data)\n\ndef iter_ents(table: str):\n    resp = fiss.fapi.get_entities(google_project, workspace, table)\n    resp.raise_for_status()\n    for item in resp.json():\n        yield item\n\ndef iter_rows(table: str):\n    for item in iter_ents(table):\n        yield item['attributes']\n\ndef get_columns(table: str) -> Dict[str, List[Any]]:\n    columns = defaultdict(list)\n    for row in iter_rows(table):\n        for key, val in row.items():\n            columns[key].append(val)\n    return dict(columns)\n\ndef delete_table(table: str):\n    rows_to_delete = [dict(entityType=e['entityType'], entityName=e['name'])\n                      for e in iter_ents(table)]\n    resp = fiss.fapi.delete_entities(google_project, workspace, rows_to_delete)\n    resp.raise_for_status()\n\ndef get_keyed_rows(table_name: str, key_column: str) -> Dict[str, Dict[str, Any]]:\n    keyed_rows = dict()\n    for row in iter_rows(table_name):\n        key = row[key_column]\n        assert key not in keyed_rows\n        keyed_rows[key] = row\n        del keyed_rows[key][key_column]\n    return keyed_rows\n\ndef keyed_row_columns(keyed_rows: Dict[str, Any]) -> Set[str]:\n    if keyed_rows:\n        random_key = set(keyed_rows.keys()).pop()\n        return set(keyed_rows[random_key].keys())\n    else:\n        return set()\n\ndef join_keyed_rows(keyed_rows_a: Dict[str, Any], keyed_rows_b: Dict[str, Any]) -> Dict[str, Any]:\n    a_columns = keyed_row_columns(keyed_rows_a)\n    b_columns = keyed_row_columns(keyed_rows_b)\n    assert not a_columns.intersection(b_columns), \"Keyed rows to join may not share columns\"\n    common_keys = set(keyed_rows_a.keys()).union(set(keyed_rows_b.keys()))\n    return {k: dict(**keyed_rows_a.get(k, {c: BLANK_CELL_VALUE for c in a_columns}),\n                    **keyed_rows_b.get(k, {c: BLANK_CELL_VALUE for c in b_columns}))\n            for k in common_keys}\n\ndef join_data_tables(new_table: str, tables_to_join: list, join_column: str):\n    keyed_rows = get_keyed_rows(tables_to_join[0], join_column)\n    for table_name in tables_to_join[1:]:\n        keyed_rows = join_keyed_rows(keyed_rows, get_keyed_rows(table_name, join_column))\n    upload_rows(new_table, [{join_column: k, **row} for k, row in keyed_rows.items()])\n\ndef create_cram_crai_table(table: str, listing: Iterable[str]):\n    crams = dict()\n    crais = dict()\n    for key in listing:\n        _, filename = key.rsplit(\"/\", 1)\n\n        parts = filename.split(\".\")\n        if 3 == len(parts):  # foo.cram.crai branch\n            sample, _, ext = parts\n        elif 2 == len(parts):  # \"foo.cram\" or \"foo.crai\" branch\n            sample, ext = parts\n        else:\n            raise ValueError(f\"Unable to parse '{filename}'\")\n\n        if \"cram\" == ext:\n            crams[sample] = key\n        elif \"crai\" == ext:\n            crais[sample] = key\n        else:\n            continue\n    samples = sorted(crams.keys())\n    upload_columns(table, dict(sample=samples,\n                               cram=[crams[s] for s in samples],\n                               crai=[crais[s] for s in samples]))\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Install gsutil on your local computer using option 2 instructions in this [document](https://support.terra.bio/hc/en-us/articles/360024056512-Uploading-to-a-workspace-Google-bucket).\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Organize your upload to Terra\nUsing instructions from the document above, you will use the gsutil tool to upload data from your local computer to\nyour Terra workspace. To effectively use the example here, we suggest you upload the data with the suggestions\nbelow.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Find the path to this workspace bucket\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "Using the os package, you can print your workspace bucket path.\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "bucket = os.environ[\"WORKSPACE_BUCKET\"]\nprint(bucket)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### Add a prefix to your bucket path to organize your data\nIn this example, we add the prefix 'test-crai-cram'. In the terminal of your computer, you will call something like:\n\n`gsutil cp /Users/Documents/Example.cram gs://your_bucket_info/test-crai-cram/`\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## Preview the data in your workspace bucket\n"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": "!gsutil ls {bucket}\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Generate a data table that links to the data in your workspace bucket\n\nTo generate a Terra data table associating crams, crais, and sample ids (e.g. \"NWD1\"), use the snippet:\n```\nlisting = [key for key in gs.list_bucket(\"my-crams\")]\ncreate_cram_crai_table(\"my-table-name\", listing)\n```\n\nFor example, the listing\n```\ngs://my-workspace-bucket/my-crams/NWD1.cram\ngs://my-workspace-bucket/my-crams/NWD1.crai\ngs://my-workspace-bucket/my-crams/NWD2.cram\ngs://my-workspace-bucket/my-crams/NWD2.crai\ngs://my-workspace-bucket/my-crams/NWD3.cram\ngs://my-workspace-bucket/my-crams/NWD3.crai\n```\nwould produce the table\n\n| sample_id | cram       | crai      |\n| --------- | ---------  | --------- |\n| NWD1      | NWD1.cram  | NWD1.crai |\n| NWD2      | NWD2.cram  | NWD2.crai |\n| NWD3      | NWD3.cram  | NWD3.crai |\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# Merge data tables across sample ids\n\nData tables can be joined across any column of shared values. For instance, the following tables can be joined with\nthe `sample_id` column:\n\n| sample_id | cram       | crai      |\n| --------- | ---------  | --------- |\n| NWD1      | NWD1.cram  | NWD1.crai |\n| NWD2      | NWD2.cram  | NWD2.crai |\n| NWD3      | NWD3.cram  | NWD3.crai |\n\n| sample_id | first_name | last_name |\n| --------- | ---------  | --------- |\n| NWD1      | Bob        | Frank     |\n| NWD2      | Sue        | Lee       |\n| NWD3      | Adrian     | Zap       |\n\n| sample_id | Diabetic   |\n| --------- | ---------  |\n| NWD1      | No         |\n| NWD3      | Yes        |\n\nThe code snippet\n```\njoin_data_tables(\"joined_table_name\", [\"cram_crai_table\", \"name_table\", \"diabetic_table\"], \"sample_id\")\n```\nproduces the combined table\n\n| sample_id | cram       | crai      | first_name | last_name | Diabetic   |\n| --------- | ---------  | --------- | ---------  | --------- | ---------  |\n| NWD1      | NWD1.cram  | NWD1.crai | Bob        | Frank     | No         |\n| NWD3      | NWD3.cram  | NWD3.crai | Adrian     | Zap       | Yes        |\n\nNote that the row for `NWD2` is missing from the combined table since it was not present in `diabetic_table`.\n\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
